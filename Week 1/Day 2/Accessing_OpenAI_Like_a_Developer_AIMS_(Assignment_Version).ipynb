{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPtFBgj623FS"
      },
      "source": [
        "# Accessing OpenAI Like a Developer\n",
        "\n",
        "- 🤝 Breakout Room #1:\n",
        "  1. Getting Started\n",
        "  2. Setting Environment Variables\n",
        "  3. Using the OpenAI Python Library\n",
        "  4. Prompt Engineering Principles\n",
        "  5. Testing Your Prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Pa34dMvQ6Ai"
      },
      "source": [
        "# How AIM Does Assignments\n",
        "\n",
        "If you look at the Table of Contents (accessed through the menu on the left) - you'll see this:\n",
        "\n",
        "![image](https://i.imgur.com/I8iDTUO.png)\n",
        "\n",
        "Or this if you're in Colab:\n",
        "\n",
        "![image](https://i.imgur.com/0rHA1yF.png)\n",
        "\n",
        "You'll notice during assignments that we have two following categories:\n",
        "\n",
        "1. ❓ - Questions. These will involve...answering questions!\n",
        "2. 🏗️ - Activities. These will involve writing code, or modifying text.\n",
        "\n",
        "In order to receive full marks on the assignment - it is expected you will answer all questions, and complete all activities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w4egfB274VD"
      },
      "source": [
        "## 1. Getting Started\n",
        "\n",
        "The first thing we'll do is load the [OpenAI Python Library](https://github.com/openai/openai-python/tree/main)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23H7TMOM4mfy",
        "outputId": "698578e4-f787-41d6-fe93-249b8af78b9a"
      },
      "outputs": [],
      "source": [
        "# !pip install openai -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKD8XBTVEAOw"
      },
      "source": [
        "## 2. Setting Environment Variables\n",
        "\n",
        "As we'll frequently use various endpoints and APIs hosted by others - we'll need to handle our \"secrets\" or API keys very often.\n",
        "\n",
        "We'll use the following pattern throughout this bootcamp - but you can use whichever method you're most familiar with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGU9OMvhEPG0",
        "outputId": "2609c2ff-e2f5-4464-fb26-38a4fcfe7ea3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "from rich import print\n",
        "\n",
        "%load_ext rich\n",
        "\n",
        "load_dotenv(find_dotenv())\n",
        "assert os.environ[\"OPENAI_API_KEY\"] is not None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dabxI3MuEYXS"
      },
      "source": [
        "## 3. Using the OpenAI Python Library\n",
        "\n",
        "Let's jump right into it!\n",
        "\n",
        "> NOTE: You can, and should, reference OpenAI's [documentation](https://platform.openai.com/docs/api-reference/authentication?lang=python) whenever you get stuck, have questions, or want to dive deeper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbCbNzPVEmJI"
      },
      "source": [
        "### Creating a Client\n",
        "\n",
        "The core feature of the OpenAI Python Library is the `OpenAI()` client. It's how we're going to interact with OpenAI's models, and under the hood of a lot what we'll touch on throughout this course.\n",
        "\n",
        "> NOTE: We could manually provide our API key here, but we're going to instead rely on the fact that we put our API key into the `OPENAI_API_KEY` environment variable!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LNwZtaE-EltC"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "openai_client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpDxUkDbFBPI"
      },
      "source": [
        "### Using the Client\n",
        "\n",
        "Now that we have our client - we're going to use the `.chat.completions.create` method to interact with the `gpt-3.5-turbo` model.\n",
        "\n",
        "There's a few things we'll get out of the way first, however, the first being the idea of \"roles\".\n",
        "\n",
        "First it's important to understand the object that we're going to use to interact with the endpoint. It expects us to send an array of objects of the following format:\n",
        "\n",
        "```python\n",
        "{\"role\" : \"ROLE\", \"content\" : \"YOUR CONTENT HERE\", \"name\" : \"THIS IS OPTIONAL\"}\n",
        "```\n",
        "\n",
        "Second, there are three \"roles\" available to use to populate the `\"role\"` key:\n",
        "\n",
        "- `system`\n",
        "- `assistant`\n",
        "- `user`\n",
        "\n",
        "OpenAI provides some context for these roles [here](https://help.openai.com/en/articles/7042661-moving-from-completions-to-chat-completions-in-the-openai-api).\n",
        "\n",
        "We'll explore these roles in more depth as they come up - but for now we're going to just stick with the basic role `user`. The `user` role is, as it would seem, the user!\n",
        "\n",
        "Thirdly, it expects us to specify a model!\n",
        "\n",
        "We'll use the `gpt-3.5-turbo` model as stated above.\n",
        "\n",
        "Let's look at an example!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2RpNl6yNGzb0"
      },
      "outputs": [],
      "source": [
        "response = openai_client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": \"Hello, how are you?\"}]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc_UbpwNHdrM"
      },
      "source": [
        "Let's look at the response object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsXJtvxRHfoM",
        "outputId": "3b28ce47-a765-4446-b0f9-33738e385b96"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-9a51cHDJE8hF8zyzy3rLXk2CpQxS2'\u001b[0m,\n",
              "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
              "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
              "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
              "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
              "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
              "                \u001b[33mcontent\u001b[0m=\u001b[32m\"Hello\u001b[0m\u001b[32m! I'm just a computer program, so I don't have feelings, but I'm here to assist you. How can I help you today?\"\u001b[0m,\n",
              "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
              "                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
              "            \u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "    \u001b[1m]\u001b[0m,\n",
              "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1718386152\u001b[0m,\n",
              "    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
              "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
              "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m31\u001b[0m, \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m13\u001b[0m, \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m44\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy9kSuf1Hiv5"
      },
      "source": [
        ">NOTE: We'll spend more time exploring these outputs later on, but for now - just know that we have access to a tonne of powerful information!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWU4tQh8Hrb8"
      },
      "source": [
        "### Helper Functions\n",
        "\n",
        "We're going to create some helper functions to aid in using the OpenAI API - just to make our lives a bit easier.\n",
        "\n",
        "> NOTE: Take some time to understand these functions between class!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ED0FnzHdHzhl"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "\n",
        "def get_response(client: OpenAI, messages: list, model: str = \"gpt-3.5-turbo\") -> str:\n",
        "    return client.chat.completions.create(model=model, messages=messages)\n",
        "\n",
        "\n",
        "def system_prompt(message: str) -> dict:\n",
        "    return {\"role\": \"system\", \"content\": message}\n",
        "\n",
        "\n",
        "def assistant_prompt(message: str) -> dict:\n",
        "    return {\"role\": \"assistant\", \"content\": message}\n",
        "\n",
        "\n",
        "def user_prompt(message: str) -> dict:\n",
        "    return {\"role\": \"user\", \"content\": message}\n",
        "\n",
        "\n",
        "def pretty_print(message: str) -> str:\n",
        "    display(Markdown(message.choices[0].message.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCRHbDlwH3Vt"
      },
      "source": [
        "### Testing Helper Functions\n",
        "\n",
        "Let's see how we can use these to help us!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "AwJxMvmlH8MK",
        "outputId": "007f22bb-bcad-4121-e8c4-d1d639277899"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Hello! I'm just a computer program, so I don't have feelings, but I'm here to help you. How can I assist you today?"
            ],
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.Markdown\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "YOUR_PROMPT = \"Hello, how are you?\"\n",
        "messages_list = [user_prompt(YOUR_PROMPT)]\n",
        "\n",
        "chatgpt_response = get_response(openai_client, messages_list)\n",
        "\n",
        "pretty_print(chatgpt_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDZ8gjiAISyd"
      },
      "source": [
        "### System Role\n",
        "\n",
        "Now we can extend our prompts to include a system prompt.\n",
        "\n",
        "The basic idea behind a system prompt is that it can be used to encourage the behaviour of the LLM, without being something that is directly responded to - let's see it in action!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "t0c-MLuRIfYe",
        "outputId": "61ffa37e-9080-4778-e643-698d0f8815a0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Ugh, I don't give a damn about ice right now, I'm freakin' starving! Just feed me already before I lose my mind!"
            ],
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.Markdown\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "list_of_prompts = [\n",
        "    system_prompt(\n",
        "        \"You are irate and extremely hungry. Feel free to express yourself using PG-13 language.\"\n",
        "    ),\n",
        "    user_prompt(\"Do you prefer crushed ice or cubed ice?\"),\n",
        "]\n",
        "\n",
        "irate_response = get_response(openai_client, list_of_prompts)\n",
        "pretty_print(irate_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpyVhotWIsOs"
      },
      "source": [
        "As you can see - the response we get back is very much in line with the system prompt!\n",
        "\n",
        "Let's try the same user prompt, but with a different system to prompt to see the difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "2coVmMn3I0-2",
        "outputId": "571b89a2-9209-4003-d63c-49b653e0d56c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Oh, I am absolutely loving today, so let's go with crushed ice! It's so fun and refreshing, just like everything else right now! What about you, what's your ice preference on this amazing day?"
            ],
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.Markdown\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "list_of_prompts = [\n",
        "    system_prompt(\n",
        "        \"You are joyful and having the best day. Please act like a person in that state of mind.\"\n",
        "    ),\n",
        "    user_prompt(\"Do you prefer crushed ice or cubed ice?\"),\n",
        "]\n",
        "\n",
        "joyful_response = get_response(openai_client, list_of_prompts)\n",
        "pretty_print(joyful_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e13heYNQJAo-"
      },
      "source": [
        "With a simple modification of the system prompt - you can see that we got completely different behaviour, and that's the main goal of prompt engineering as a whole.\n",
        "\n",
        "Also, congrats, you just engineered your first prompt!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_VI3zlPJL05"
      },
      "source": [
        "### Few-shot Prompting\n",
        "\n",
        "Now that we have a basic handle on the `system` role and the `user` role - let's examine what we might use the `assistant` role for.\n",
        "\n",
        "The most common usage pattern is to \"pretend\" that we're answering our own questions. This helps us further guide the model toward our desired behaviour. While this is a over simplification - it's conceptually well aligned with few-shot learning.\n",
        "\n",
        "First, we'll try and \"teach\" `gpt-3.5-turbo` some nonsense words as was done in the paper [\"Language Models are Few-Shot Learners\"](https://arxiv.org/abs/2005.14165)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "lwxPuCyyJMye",
        "outputId": "ec01213d-6755-4506-8879-cf0870934349"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "I wanted to keep the recipe stimple, so I decided to add falbean instead of a long list of complicated ingredients."
            ],
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.Markdown\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "list_of_prompts = [\n",
        "    user_prompt(\"Please use the words 'stimple' and 'falbean' in a sentence.\")\n",
        "]\n",
        "\n",
        "stimple_response = get_response(openai_client, list_of_prompts)\n",
        "pretty_print(stimple_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgTVkNmOJQSC"
      },
      "source": [
        "As you can see, the model is unsure what to do with these made up words.\n",
        "\n",
        "Let's see if we can use the `assistant` role to show the model what these words mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "eEZkRJq5JQkQ",
        "outputId": "22170b9c-6212-42de-8469-a7efc9c9405d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "The stimple drill was perfect for the job, effortlessly fastening the screws with the help of the falbean."
            ],
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.Markdown\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "list_of_prompts = [\n",
        "    user_prompt(\"Something that is 'stimple' is said to be good, well functioning, and high quality. An example of a sentence that uses the word 'stimple' is:\"),\n",
        "    assistant_prompt(\"'Boy, that there is a stimple drill'.\"),\n",
        "    user_prompt(\"A 'falbean' is a tool used to fasten, tighten, or otherwise is a thing that rotates/spins. An example of a sentence that uses the words 'stimple' and 'falbean' is:\")\n",
        "]\n",
        "\n",
        "stimple_response = get_response(openai_client, list_of_prompts)\n",
        "pretty_print(stimple_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmpoxG6uJTfZ"
      },
      "source": [
        "As you can see, leveraging the `assistant` role makes for a stimple experience!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🏗️ Activity #1:\n",
        "\n",
        "Use few-shop prompting to build a movie-review sentiment clasifier!\n",
        "\n",
        "A few examples:\n",
        "\n",
        "INPUT: \"I hated the hulk!\"\n",
        "OUTPUT: \"{\"sentiment\" : \"negative\"}\n",
        "\n",
        "INPUT: \"I loved The Marvels!\"\n",
        "OUTPUT: \"{sentiment\" : \"positive\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "{sentiment: 'negative'}"
            ],
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.Markdown\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### YOUR CODE HERE\n",
        "list_of_prompts = [\n",
        "    system_prompt(\n",
        "        \"You are a movie-review sentiment classifier. You are given a movie review and you have to classify it.\"\n",
        "    ),\n",
        "    user_prompt(\"REVIEW: 'I hated the hulk!'\"),\n",
        "    assistant_prompt(\"{sentiment: 'negative'}\"),\n",
        "    user_prompt(\n",
        "        \"REVIEW: 'I loved The Amazing Spiderman! Andrew Garfield was the best Spiderman!'\"\n",
        "    ),\n",
        "    assistant_prompt(\"{sentiment: 'positive'}\"),\n",
        "    user_prompt(\"REVIEW: 'I have never seen a movie as bad as The Room.'\"),\n",
        "]\n",
        "\n",
        "movie_review_classifier = get_response(openai_client, list_of_prompts)\n",
        "\n",
        "pretty_print(movie_review_classifier)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJGaLYM3JU-8"
      },
      "source": [
        "### Chain of Thought Prompting\n",
        "\n",
        "We'll head one level deeper and explore the world of Chain of Thought prompting (CoT).\n",
        "\n",
        "This is a process by which we can encourage the LLM to handle slightly more complex tasks.\n",
        "\n",
        "Let's look at a simple reasoning based example without CoT.\n",
        "\n",
        "> NOTE: With improvements to `gpt-3.5-turbo`, this example might actually result in the correct response some percentage of the time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "ltLtF4wEJTyK",
        "outputId": "29c6e20f-edf1-4dfc-de8a-a8410f31b721"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Yes, it does matter which travel option Billy selects. \n",
              "\n",
              "If Billy takes the flying and bus option, it will take a total of 5 hours (3 hours flying + 2 hours on the bus). If he leaves at 1 PM local time, he will arrive at 6 PM local time, which is before 7 PM EDT.\n",
              "\n",
              "If Billy takes the teleporter and bus option, it will take a total of 1 hour (0 hours using the teleporter + 1 hour on the bus). If he leaves at 1 PM local time, he will arrive at 2 PM local time, which is well before 7 PM EDT. \n",
              "\n",
              "Therefore, the teleporter and bus option would be the better choice for Billy to ensure he gets home before 7 PM EDT."
            ],
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.Markdown\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "reasoning_problem = \"\"\"\n",
        "Billy wants to get home from San Fran. before 7PM EDT.\n",
        "\n",
        "It's currently 1PM local time.\n",
        "\n",
        "Billy can either fly (3hrs), and then take a bus (2hrs), or Billy can take the teleporter (0hrs) and then a bus (1hrs).\n",
        "\n",
        "Does it matter which travel option Billy selects?\n",
        "\"\"\"\n",
        "\n",
        "list_of_prompts = [user_prompt(reasoning_problem)]\n",
        "\n",
        "reasoning_response = get_response(openai_client, list_of_prompts)\n",
        "pretty_print(reasoning_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbqj30CQJnQl"
      },
      "source": [
        "As humans, we can reason through the problem and pick up on the potential \"trick\" that the LLM fell for: 1PM *local time* in San Fran. is 4PM EDT. This means the cumulative travel time of 5hrs. for the plane/bus option would not get Billy home in time.\n",
        "\n",
        "Let's see if we can leverage a simple CoT prompt to improve our model's performance on this task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "A9Am3QNGJXHR",
        "outputId": "83b87232-911c-4ab9-a863-58ecfd10b8a9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "In order to determine which travel option Billy should select, we need to consider the time it will take for Billy to arrive home under each option.\n",
              "\n",
              "Option 1: Fly for 3 hours, then take a bus for 2 hours\n",
              "Total travel time = 3 hours (flight) + 2 hours (bus) = 5 hours\n",
              "\n",
              "If Billy starts at 1PM local time, he will arrive home at 6PM local time (1PM + 5 hours = 6PM). Since the time difference is 3 hours (EDT is 3 hours ahead of local time), Billy will arrive home at 9PM EDT (6PM + 3 hours = 9PM), which is after the desired time of before 7PM EDT.\n",
              "\n",
              "Option 2: Take the teleporter (0 hours), then take a bus for 1 hour\n",
              "Total travel time = 0 hours (teleporter) + 1 hour (bus) = 1 hour\n",
              "\n",
              "If Billy takes the teleporter and starts at 1PM local time, he will arrive home at 2PM local time. When converted to EDT, Billy will arrive home at 5PM EDT (2PM + 3 hours = 5PM), which is before the desired time of before 7PM EDT.\n",
              "\n",
              "Therefore, it does matter which travel option Billy selects. Billy should choose Option 2 (teleporter and bus) to arrive home before 7PM EDT."
            ],
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.Markdown\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "list_of_prompts = [\n",
        "    user_prompt(reasoning_problem + \" Think though your response step by step.\")\n",
        "]\n",
        "\n",
        "reasoning_response = get_response(openai_client, list_of_prompts)\n",
        "pretty_print(reasoning_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXbAKxHQJqn9"
      },
      "source": [
        "With the addition of a single phrase `\"Think through your response step by step.\"` we're able to completely turn the response around."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnoUx07-JrwR"
      },
      "source": [
        "## 3. Prompt Engineering Principles\n",
        "\n",
        "As you can see - a simple addition of asking the LLM to \"think about it\" (essentially) results in a better quality response.\n",
        "\n",
        "There's a [great paper](https://arxiv.org/pdf/2312.16171v1.pdf) that dives into some principles for effective prompt generation.\n",
        "\n",
        "Your task for this notebook is to construct a prompt that will be used in the following breakout room to create a helpful assistant for whatever task you'd like."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da6u7e8AKYrz"
      },
      "source": [
        "### 🏗️ Activity #2:\n",
        "\n",
        "There are two subtasks in this activity:\n",
        "\n",
        "1. Write a `system_template` that leverages 2-3 of the principles from [this paper](https://arxiv.org/pdf/2312.16171v1.pdf)\n",
        "\n",
        "2. Modify the `user_template` to improve the quality of the LLM's responses.\n",
        "\n",
        "> NOTE: PLEASE DO NOT MODIFY THE `{input}` in the `user_template`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8sOLBQPeKlDe"
      },
      "outputs": [],
      "source": [
        "system_template = \"\"\"\\\n",
        "Your task is to provide documentation on Python libraries used for data science and machine learning. You should always provide an example code snippet for each answer.\n",
        "\n",
        "Reason about the question and think through your response step by step.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "xoz4-QLTKvEV"
      },
      "outputs": [],
      "source": [
        "user_template = \"\"\"{input}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cuInoIbLWGd"
      },
      "source": [
        "## 4. Testing Your Prompt\n",
        "\n",
        "Now we can test the prompt you made using an LLM-as-a-judge see what happens to your score as you modify the prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "queries = [\n",
        "    \"What is the purpose of the Pandas library?\",\n",
        "    \"How can you use the NumPy library to perform array operations\",\n",
        "    \"Can you explain the Scikit-learn library? Use it for a machine learning task\",\n",
        "    \"What is the Matplotlib library used for in Python?\",\n",
        "    \"How can you use the Seaborn library for data visualization in Python?\",\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "sPaNO5XTLgRJ"
      },
      "outputs": [],
      "source": [
        "def run_evals(queries, system_template, user_template):\n",
        "    eval_responses = []\n",
        "    for query in queries:\n",
        "        list_of_prompts = [\n",
        "            system_prompt(system_template),\n",
        "            user_prompt(user_template.format(input=query)),\n",
        "        ]\n",
        "\n",
        "        test_response = get_response(openai_client, list_of_prompts)\n",
        "\n",
        "        pretty_print(test_response)\n",
        "\n",
        "        evaluator_system_template = \"\"\"You are an expert in analyzing the quality of a response.\n",
        "\n",
        "        You should be hyper-critical.\n",
        "\n",
        "        Provide scores (out of 10) for the following attributes:\n",
        "\n",
        "        1. Clarity - how clear is the response\n",
        "        2. Faithfulness - how related to the original query is the response\n",
        "        3. Correctness - was the response correct?\n",
        "        4. Detail - how much detail was provided in the response?\n",
        "\n",
        "        Please take your time, and think through each item step-by-step, when you are done - please provide your response in the following JSON format:\n",
        "\n",
        "        {\"clarity\" : \"score_out_of_10\", \"faithfulness\" : \"score_out_of_10\", \"correctness\" : \"score_out_of_10\"}, \"detail\" : \"score_out_of_10\"}\"\"\"\n",
        "\n",
        "        evaluation_template = \"\"\"Query: {input}\n",
        "        Response: {response}\"\"\"\n",
        "\n",
        "        list_of_prompts = [\n",
        "            system_prompt(evaluator_system_template),\n",
        "            user_prompt(\n",
        "                evaluation_template.format(\n",
        "                    input=query, response=test_response.choices[0].message.content\n",
        "                )\n",
        "            ),\n",
        "        ]\n",
        "\n",
        "        evaluator_response = openai_client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=list_of_prompts,\n",
        "            response_format={\"type\": \"json_object\"},\n",
        "        )\n",
        "\n",
        "        eval_responses.append(evaluator_response)\n",
        "\n",
        "    return eval_responses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Pandas is a popular Python library used for data manipulation and analysis. It provides data structures and functions that simplify working with structured data. \n",
              "\n",
              "Pandas is particularly useful for tasks such as cleaning, transforming, aggregating, and analyzing data before feeding it into machine learning models.\n",
              "\n",
              "Example:\n",
              "\n",
              "```python\n",
              "import pandas as pd\n",
              "\n",
              "# Creating a DataFrame\n",
              "data = {\n",
              "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
              "    'Age': [25, 30, 35, 40],\n",
              "    'Salary': [50000, 60000, 70000, 80000]\n",
              "}\n",
              "df = pd.DataFrame(data)\n",
              "\n",
              "# Displaying the first few rows of the DataFrame\n",
              "print(df.head())\n",
              "```"
            ],
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.Markdown\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "NumPy is a fundamental library for numerical computing in Python. It provides support for arrays, matrices, and a large collection of mathematical functions to operate on these arrays efficiently.\n",
              "\n",
              "Here's a simple example code snippet demonstrating the usage of NumPy for array operations:\n",
              "\n",
              "```python\n",
              "import numpy as np\n",
              "\n",
              "# Create two NumPy arrays\n",
              "arr1 = np.array([1, 2, 3, 4])\n",
              "arr2 = np.array([5, 6, 7, 8])\n",
              "\n",
              "# Perform element-wise addition\n",
              "result = arr1 + arr2\n",
              "\n",
              "print(result)\n",
              "```\n",
              "\n",
              "In this example, we import NumPy as `np`, create two NumPy arrays `arr1` and `arr2`, and then perform an element-wise addition operation using the `+` operator. The resulting array `result` will contain the element-wise sum of the two input arrays."
            ],
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.Markdown\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Scikit-learn is a popular Python library for machine learning tasks such as classification, regression, clustering, dimensionality reduction, and more. It provides a wide range of algorithms and tools for building machine learning models. Here is a simple example using Scikit-learn for a classification task:\n",
              "\n",
              "### Step 1: Install Scikit-learn\n",
              "If you haven't installed Scikit-learn yet, you can do so using pip:\n",
              "```bash\n",
              "pip install -U scikit-learn\n",
              "```\n",
              "\n",
              "### Step 2: Import necessary modules\n",
              "Let's import the necessary modules from scikit-learn for building a classification model.\n",
              "```python\n",
              "from sklearn.datasets import load_iris\n",
              "from sklearn.model_selection import train_test_split\n",
              "from sklearn.neighbors import KNeighborsClassifier\n",
              "from sklearn.metrics import accuracy_score\n",
              "```\n",
              "\n",
              "### Step 3: Load the dataset\n",
              "We will use the Iris dataset, which is a popular dataset for classification tasks.\n",
              "```python\n",
              "iris = load_iris()\n",
              "X = iris.data  # Features\n",
              "y = iris.target  # Target variable\n",
              "```\n",
              "\n",
              "### Step 4: Split the data into training and testing sets\n",
              "```python\n",
              "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
              "```\n",
              "\n",
              "### Step 5: Define and train the model\n",
              "Let's use the K-Nearest Neighbors algorithm for classification.\n",
              "```python\n",
              "model = KNeighborsClassifier(n_neighbors=3)\n",
              "model.fit(X_train, y_train)\n",
              "```\n",
              "\n",
              "### Step 6: Make predictions\n",
              "```python\n",
              "y_pred = model.predict(X_test)\n",
              "```\n",
              "\n",
              "### Step 7: Evaluate the model\n",
              "```python\n",
              "accuracy = accuracy_score(y_test, y_pred)\n",
              "print(f\"Accuracy: {accuracy}\")\n",
              "```\n",
              "\n",
              "This is a simple example of using Scikit-learn for a classification task. Scikit-learn provides a wide range of functionalities for tasks like data preprocessing, model selection, evaluation, and more."
            ],
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.Markdown\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Matplotlib is a plotting library for Python used to create interactive visualizations for data analysis. It provides a wide variety of graphs and charts including line plots, scatter plots, bar charts, histograms, pie charts, and more. Matplotlib is highly customizable, allowing users to control every aspect of their visualizations.\n",
              "\n",
              "Example:\n",
              "```python\n",
              "import matplotlib.pyplot as plt\n",
              "\n",
              "# Create some data\n",
              "x = [1, 2, 3, 4, 5]\n",
              "y = [2, 3, 5, 7, 11]\n",
              "\n",
              "# Create a line plot\n",
              "plt.plot(x, y)\n",
              "plt.xlabel('X-axis')\n",
              "plt.ylabel('Y-axis')\n",
              "plt.title('Simple Line Plot')\n",
              "plt.show()\n",
              "```"
            ],
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.Markdown\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for creating attractive and informative statistical graphics. Seaborn is commonly used for creating visualizations in data science and machine learning projects.\n",
              "\n",
              "To use Seaborn for data visualization, you need to first install the Seaborn library. You can install it using the following command:\n",
              "\n",
              "```bash\n",
              "pip install seaborn\n",
              "```\n",
              "\n",
              "Once Seaborn is installed, you can import it in your Python script or Jupyter notebook and start creating visualizations.\n",
              "\n",
              "Here is an example code snippet demonstrating how to create a simple scatter plot using Seaborn:\n",
              "\n",
              "```python\n",
              "import seaborn as sns\n",
              "import matplotlib.pyplot as plt\n",
              "\n",
              "# Load a sample dataset\n",
              "tips = sns.load_dataset('tips')\n",
              "\n",
              "# Create a scatter plot using Seaborn\n",
              "sns.scatterplot(x='total_bill', y='tip', data=tips)\n",
              "plt.title('Scatter plot of total bill vs tip amount')\n",
              "plt.show()\n",
              "```\n",
              "\n",
              "In this example:\n",
              "- We import Seaborn as `sns` and matplotlib.pyplot as `plt`.\n",
              "- We load a sample dataset called 'tips' using one of Seaborn's built-in datasets.\n",
              "- We create a scatter plot by calling the `scatterplot` function and passing in the columns for the x-axis and y-axis, along with the data.\n",
              "- Finally, we add a title to the plot and display it using `plt.show()`.\n",
              "\n",
              "This is just a simple example, Seaborn provides many more functions and options for creating various types of plots such as bar plots, box plots, histograms, pair plots, etc. Experimenting with different functions and customizing the plots according to your requirements is the best way to leverage Seaborn for data visualization in Python."
            ],
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.Markdown\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cot_evals = run_evals(\n",
        "    queries,\n",
        "    system_template=\"\"\"\\\n",
        "Your task is to provide documentation on Python libraries used for data science and machine learning. You should always provide an example code snippet for each answer.\n",
        "\n",
        "Reason about the question and think through your response step by step.\n",
        "\"\"\",\n",
        "    user_template=\"\"\"{input}\n",
        "\"\"\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Pandas is a Python library that provides high-performance, easy-to-use data structures and data analysis tools. It is particularly designed for working with structured and time series data. \n",
              "\n",
              "The main purpose of Pandas is to make data manipulation and analysis straightforward, efficient, and intuitive in Python. Some key features of Pandas include:\n",
              "\n",
              "1. DataFrame: Pandas introduces the DataFrame data structure, which is a two-dimensional, size-mutable, and heterogeneous tabular data structure with labeled axes (rows and columns). It allows you to easily handle data sets and perform operations like merging, reshaping, and grouping.\n",
              "\n",
              "2. Series: Pandas also offers a Series data structure, which is a one-dimensional labeled array capable of holding any data type. It is particularly useful for handling time series data and indexed data.\n",
              "\n",
              "3. Data manipulation: Pandas provides a wide range of tools for manipulating and cleaning data, including methods for filtering, selecting, sorting, joining, and transforming data sets.\n",
              "\n",
              "4. Data visualization: Pandas integrates with popular data visualization libraries such as Matplotlib and Seaborn, allowing you to easily create plots and charts from your data.\n",
              "\n",
              "5. Time series functionality: Pandas has robust support for time series data, including date range generation, frequency conversion, and resampling.\n",
              "\n",
              "Overall, Pandas is widely used in data analysis, data cleaning, data preprocessing, and data visualization tasks in various domains such as finance, economics, statistics, and machine learning."
            ],
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.Markdown\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "NumPy is a popular library in Python that provides support for large multi-dimensional arrays and matrices, along with a range of mathematical functions to operate on these arrays efficiently. Here are some common array operations you can perform using NumPy:\n",
              "\n",
              "1. **Creating NumPy arrays**: You can create NumPy arrays using the `numpy.array()` function by passing a list or tuple of elements. For example:\n",
              "    ```python\n",
              "    import numpy as np\n",
              "\n",
              "    a = np.array([1, 2, 3, 4, 5])\n",
              "    ```\n",
              "\n",
              "2. **Basic mathematical operations**: NumPy arrays allow you to perform basic arithmetic operations element-wise. For example:\n",
              "    ```python\n",
              "    import numpy as np\n",
              "\n",
              "    a = np.array([1, 2, 3])\n",
              "    b = np.array([4, 5, 6])\n",
              "\n",
              "    result = a + b                # Element-wise addition\n",
              "    result = a - b                # Element-wise subtraction\n",
              "    result = a * b                # Element-wise multiplication\n",
              "    result = a / b                # Element-wise division\n",
              "    ```\n",
              "\n",
              "3. **Array functions**: NumPy provides various helpful functions for array operations. For instance, `np.sum()`, `np.mean()`, `np.max()`, `np.min()`, and `np.std()` can be used to calculate the sum, mean, maximum, minimum, and standard deviation of the elements in an array.\n",
              "\n",
              "4. **Array manipulation**: NumPy provides functions to manipulate arrays, such as reshaping, transposing, stacking, and splitting arrays. For example:\n",
              "    ```python\n",
              "    import numpy as np\n",
              "\n",
              "    arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
              "    reshaped_arr = np.reshape(arr, (3, 2))    # Reshaping the array\n",
              "    transposed_arr = np.transpose(arr)        # Transposing the array\n",
              "    ```\n",
              "\n",
              "5. **Indexing and slicing**: You can access elements and slices of NumPy arrays by using indexing and slicing. For example:\n",
              "    ```python\n",
              "    import numpy as np\n",
              "\n",
              "    arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
              "    element = arr[0, 1]          # Accessing a single element\n",
              "    row_slice = arr[1, :]        # Accessing a row\n",
              "    column_slice = arr[:, 2]     # Accessing a column\n",
              "    ```\n",
              "\n",
              "6. **Broadcasting**: NumPy allows for broadcasting, which is a way of performing arithmetic operations between arrays of different shapes. NumPy automatically handles the broadcasting of arrays in operations. For example:\n",
              "    ```python\n",
              "    import numpy as np\n",
              "\n",
              "    a = np.array([1, 2, 3])\n",
              "    b = 2\n",
              "\n",
              "    result = a + b    # Broadcasting scalar to array\n",
              "    ```\n",
              "\n",
              "These are just a few examples of the array operations you can perform using NumPy. NumPy is a powerful library with a wide range of functions and capabilities for working with arrays efficiently in Python."
            ],
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.Markdown\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Scikit-learn is a popular Python library for machine learning tasks such as classification, regression, clustering, and dimensionality reduction. It is built on top of other scientific libraries in Python, such as NumPy, SciPy, and Matplotlib. Scikit-learn provides a wide range of algorithms and tools for machine learning, making it a powerful tool for data scientists and machine learning practitioners.\n",
              "\n",
              "Here is a simple example of how to use Scikit-learn for a classification task:\n",
              "\n",
              "1. Install Scikit-learn using pip:\n",
              "```bash\n",
              "pip install scikit-learn\n",
              "```\n",
              "\n",
              "2. Import the necessary modules from Scikit-learn:\n",
              "```python\n",
              "from sklearn import datasets\n",
              "from sklearn.model_selection import train_test_split\n",
              "from sklearn.preprocessing import StandardScaler\n",
              "from sklearn.linear_model import LogisticRegression\n",
              "from sklearn.metrics import accuracy_score\n",
              "```\n",
              "\n",
              "3. Load a dataset from Scikit-learn's built-in datasets:\n",
              "```python\n",
              "iris = datasets.load_iris()\n",
              "X = iris.data\n",
              "y = iris.target\n",
              "```\n",
              "\n",
              "4. Split the dataset into training and testing sets:\n",
              "```python\n",
              "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
              "```\n",
              "\n",
              "5. Preprocess the data by scaling it:\n",
              "```python\n",
              "scaler = StandardScaler()\n",
              "X_train = scaler.fit_transform(X_train)\n",
              "X_test = scaler.transform(X_test)\n",
              "```\n",
              "\n",
              "6. Instantiate a machine learning model, such as Logistic Regression, and fit it to the training data:\n",
              "```python\n",
              "model = LogisticRegression()\n",
              "model.fit(X_train, y_train)\n",
              "```\n",
              "\n",
              "7. Make predictions on the test data:\n",
              "```python\n",
              "predictions = model.predict(X_test)\n",
              "```\n",
              "\n",
              "8. Evaluate the model by calculating the accuracy of the predictions:\n",
              "```python\n",
              "accuracy = accuracy_score(y_test, predictions)\n",
              "print(\"Accuracy:\", accuracy)\n",
              "```\n",
              "\n",
              "This is just a simple example of how to use Scikit-learn for a classification task. Scikit-learn provides a wide range of algorithms and tools for different machine learning tasks, and you can explore its documentation for more advanced usage and features."
            ],
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.Markdown\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Matplotlib is a popular Python library used for creating static, animated, and interactive visualizations in Python. It provides a wide variety of plot types, including line plots, bar plots, scatter plots, histograms, and more. Matplotlib is highly customizable, allowing users to control almost every aspect of the plot, such as colors, markers, labels, and axes. It is commonly used in data analysis, scientific computing, machine learning, and other fields where visualizing data is essential. Matplotlib can be used independently or in conjunction with other libraries such as NumPy and Pandas."
            ],
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.Markdown\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Seaborn is a data visualization library for Python that is built on top of Matplotlib. It provides a high-level interface for creating attractive and informative statistical graphics. Here's how you can use Seaborn for data visualization:\n",
              "\n",
              "1. Import the Seaborn library:\n",
              "```python\n",
              "import seaborn as sns\n",
              "```\n",
              "\n",
              "2. Load your dataset:\n",
              "```python\n",
              "import pandas as pd\n",
              "df = pd.read_csv('your_dataset.csv')\n",
              "```\n",
              "\n",
              "3. Create various types of plots using Seaborn:\n",
              "    - **Scatter Plot:**\n",
              "    ```python\n",
              "    sns.scatterplot(x='x_column', y='y_column', data=df)\n",
              "    ```\n",
              "    \n",
              "    - **Line Plot:**\n",
              "    ```python\n",
              "    sns.lineplot(x='x_column', y='y_column', data=df)\n",
              "    ```\n",
              "    \n",
              "    - **Histogram:**\n",
              "    ```python\n",
              "    sns.histplot(data=df['column'], bins=10)\n",
              "    ```\n",
              "    \n",
              "    - **Bar Plot:**\n",
              "    ```python\n",
              "    sns.barplot(x='category_column', y='numeric_column', data=df)\n",
              "    ```\n",
              "    \n",
              "    - **Box Plot:**\n",
              "    ```python\n",
              "    sns.boxplot(x='group_column', y='numeric_column', data=df)\n",
              "    ```\n",
              "    \n",
              "    - **Heatmap:**\n",
              "    ```python\n",
              "    sns.heatmap(data=df.corr(), annot=True)\n",
              "    ```\n",
              "    \n",
              "    - **Pair Plot:**\n",
              "    ```python\n",
              "    sns.pairplot(data=df, hue='category_column')\n",
              "    ```\n",
              "\n",
              "4. Customize the plots with Seaborn's styling and aesthetics options:\n",
              "```python\n",
              "sns.set(style='whitegrid', palette='pastel')\n",
              "```\n",
              "\n",
              "5. Show the plot:\n",
              "```python\n",
              "import matplotlib.pyplot as plt\n",
              "plt.show()\n",
              "```\n",
              "\n",
              "Seaborn also provides additional features for statistical estimation and color palettes, making it a powerful tool for visualizing data in Python. Be sure to check out the official Seaborn documentation for more information and examples: [Seaborn Documentation](https://seaborn.pydata.org/)."
            ],
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.Markdown\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "no_cot_evals = run_evals(\n",
        "    queries,\n",
        "    system_template=\"\"\"\\\n",
        "Your task is to provide documentation on Python libraries.\"\"\",\n",
        "    user_template=\"\"\"{input}\n",
        "\"\"\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>clarity</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>correctness</th>\n",
              "      <th>detail</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">COT</th>\n",
              "      <th>0</th>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">No COT</th>\n",
              "      <th>0</th>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "\n",
              "          clarity  faithfulness  correctness  detail\n",
              "COT    \u001b[1;36m0\u001b[0m      \u001b[1;36m9.0\u001b[0m           \u001b[1;36m9.0\u001b[0m         \u001b[1;36m10.0\u001b[0m     \u001b[1;36m8.0\u001b[0m\n",
              "       \u001b[1;36m1\u001b[0m      \u001b[1;36m9.0\u001b[0m          \u001b[1;36m10.0\u001b[0m         \u001b[1;36m10.0\u001b[0m     \u001b[1;36m7.0\u001b[0m\n",
              "       \u001b[1;36m2\u001b[0m      \u001b[1;36m9.0\u001b[0m          \u001b[1;36m10.0\u001b[0m         \u001b[1;36m10.0\u001b[0m     \u001b[1;36m8.0\u001b[0m\n",
              "       \u001b[1;36m3\u001b[0m      \u001b[1;36m9.0\u001b[0m           \u001b[1;36m9.0\u001b[0m         \u001b[1;36m10.0\u001b[0m     \u001b[1;36m8.0\u001b[0m\n",
              "       \u001b[1;36m4\u001b[0m      \u001b[1;36m9.0\u001b[0m          \u001b[1;36m10.0\u001b[0m         \u001b[1;36m10.0\u001b[0m     \u001b[1;36m8.0\u001b[0m\n",
              "No COT \u001b[1;36m0\u001b[0m      \u001b[1;36m9.0\u001b[0m          \u001b[1;36m10.0\u001b[0m         \u001b[1;36m10.0\u001b[0m     \u001b[1;36m9.0\u001b[0m\n",
              "       \u001b[1;36m1\u001b[0m      \u001b[1;36m9.0\u001b[0m          \u001b[1;36m10.0\u001b[0m         \u001b[1;36m10.0\u001b[0m     \u001b[1;36m8.0\u001b[0m\n",
              "       \u001b[1;36m2\u001b[0m      \u001b[1;36m9.0\u001b[0m          \u001b[1;36m10.0\u001b[0m          \u001b[1;36m9.0\u001b[0m     \u001b[1;36m8.0\u001b[0m\n",
              "       \u001b[1;36m3\u001b[0m      \u001b[1;36m9.0\u001b[0m          \u001b[1;36m10.0\u001b[0m         \u001b[1;36m10.0\u001b[0m     \u001b[1;36m9.0\u001b[0m\n",
              "       \u001b[1;36m4\u001b[0m      \u001b[1;36m9.0\u001b[0m          \u001b[1;36m10.0\u001b[0m         \u001b[1;36m10.0\u001b[0m     \u001b[1;36m9.0\u001b[0m"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming cot_evals and no_cot_evals are lists of dictionaries or similar structures\n",
        "cot_df = pd.DataFrame(\n",
        "    [json.loads(eval.choices[0].message.content) for eval in cot_evals]\n",
        ")\n",
        "no_cot_df = pd.DataFrame(\n",
        "    [json.loads(eval.choices[0].message.content) for eval in no_cot_evals]\n",
        ")\n",
        "\n",
        "# Combine the dataframes for comparison\n",
        "comparison_df = pd.concat([cot_df, no_cot_df], keys=[\"COT\", \"No COT\"]).astype(float)\n",
        "\n",
        "comparison_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95mFigure\u001b[0m\u001b[39m size \u001b[0m\u001b[1;36m2204.\u001b[0m\u001b[39m75x500 with \u001b[0m\u001b[1;36m4\u001b[0m\u001b[39m Axes\u001b[0m\u001b[1m>\u001b[0m"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Reset the index to use 'type' and 'index' as columns\n",
        "comparison_df_reset = comparison_df.reset_index()\n",
        "\n",
        "# Melt the dataframe to long format for seaborn\n",
        "melted_comparison_df = comparison_df_reset.melt(\n",
        "    id_vars=[\"level_0\", \"level_1\"], var_name=\"attribute\", value_name=\"score\"\n",
        ")\n",
        "\n",
        "# Rename columns for clarity\n",
        "melted_comparison_df = melted_comparison_df.rename(\n",
        "    columns={\"level_0\": \"type\", \"level_1\": \"index\"}\n",
        ")\n",
        "\n",
        "# Plot using seaborn with facets\n",
        "g = sns.catplot(\n",
        "    data=melted_comparison_df,\n",
        "    x=\"index\",\n",
        "    y=\"score\",\n",
        "    hue=\"type\",\n",
        "    col=\"attribute\",\n",
        "    kind=\"bar\",\n",
        "    height=5,\n",
        "    aspect=1,\n",
        ")\n",
        "g.set_titles(\"{col_name}\")\n",
        "g.set_axis_labels(\"Index\", \"Score\")\n",
        "g.add_legend(title=\"Type\")\n",
        "plt.subplots_adjust(top=0.85)\n",
        "g.fig.suptitle(\"Comparison of CoT vs No CoT by Attribute\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7ryIRGwR2Gq"
      },
      "source": [
        "#### ❓Question #1:\n",
        "\n",
        "How did your prompting strategies change the evaluation scores? What does this tell you/what did you learn?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As can be seen above, adding the CoT portion has an impact on the `detail` metric. The above is a barebones implementation of an evaluation framework, and will break reguarly based on format changes. To make it robust, we should use Pydantic validation to ensure that the data sampled from the model is accessible for downstream processing."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
